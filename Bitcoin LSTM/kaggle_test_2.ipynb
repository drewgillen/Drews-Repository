{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "file = 'ETH_Small.csv'\r\n",
    "\r\n",
    "df = pd.read_csv(file)\r\n",
    "\r\n",
    "print(df.head())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "# Plots a dataframe using matplotlib\r\n",
    "def mpl_plot(df):\r\n",
    "\r\n",
    "    #Plot the file on a graph    \r\n",
    "    df.plot(\r\n",
    "        figsize = (12,10),\r\n",
    "        title = 'Stock Price Close Minute Data',\r\n",
    "        xlabel = 'Time (mins)',\r\n",
    "        ylabel = 'Price ($)',\r\n",
    "        y = 'c',\r\n",
    "        x = 't',\r\n",
    "        grid = True,\r\n",
    "        label = 'Minute Close',\r\n",
    "    )\r\n",
    "\r\n",
    "    plt.show()\r\n",
    "\r\n",
    "plot = mpl_plot(df)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "price = df[['c']]\r\n",
    "\r\n",
    "print(price)\r\n",
    "\r\n",
    "price.info()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\r\n",
    "\r\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\r\n",
    "\r\n",
    "#price['c'] = scaler.fit_transform(price['c'].values.reshape(-1,1))\r\n",
    "#price['c'] = scaler.fit_transform(price['c'])\r\n",
    "\r\n",
    "#print(price)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# This somehow splits the data up into a numpy array along with the sequences\r\n",
    "\r\n",
    "def split_data(stock, lookback):\r\n",
    "    data_raw = stock.to_numpy() # convert to numpy array\r\n",
    "    data = []\r\n",
    "    \r\n",
    "    # create all possible sequences of length seq_len\r\n",
    "    for index in range(len(data_raw) - lookback): \r\n",
    "        data.append(data_raw[index: index + lookback])\r\n",
    "    \r\n",
    "    data = np.array(data);\r\n",
    "    test_set_size = int(np.round(0.2*data.shape[0]));\r\n",
    "    train_set_size = data.shape[0] - (test_set_size);\r\n",
    "    \r\n",
    "    x_train = data[:train_set_size,:-1,:]\r\n",
    "    y_train = data[:train_set_size,-1,:]\r\n",
    "    \r\n",
    "    x_test = data[train_set_size:,:-1]\r\n",
    "    y_test = data[train_set_size:,-1,:]\r\n",
    "    \r\n",
    "    return [x_train, y_train, x_test, y_test]\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lookback = 120 # choose sequence length\r\n",
    "\r\n",
    "\r\n",
    "x_train, y_train, x_test, y_test = split_data(price, lookback)\r\n",
    "\r\n",
    "print(type(x_train))\r\n",
    "\r\n",
    "print('x_train.shape = ',x_train.shape)\r\n",
    "print('y_train.shape = ',y_train.shape)\r\n",
    "print('x_test.shape = ',x_test.shape)\r\n",
    "print('y_test.shape = ',y_test.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load the data into a torch tensor"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\n",
    "#print(torch.cuda.get_device_name(torch.cuda.current_device()))\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "x_train = torch.from_numpy(x_train).type(torch.Tensor)\r\n",
    "x_test = torch.from_numpy(x_test).type(torch.Tensor)\r\n",
    "y_train_lstm = torch.from_numpy(y_train).type(torch.Tensor)\r\n",
    "y_test_lstm = torch.from_numpy(y_test).type(torch.Tensor)\r\n",
    "y_train_gru = torch.from_numpy(y_train).type(torch.Tensor)\r\n",
    "y_test_gru = torch.from_numpy(y_test).type(torch.Tensor)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hyper Parameters for Model and Training Loop"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "input_dim = 1\r\n",
    "hidden_dim = 128\r\n",
    "num_layers = 2\r\n",
    "output_dim = 1\r\n",
    "num_epochs = 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "class LSTM(nn.Module):\r\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\r\n",
    "        super(LSTM, self).__init__()\r\n",
    "        self.hidden_dim = hidden_dim\r\n",
    "        self.num_layers = num_layers\r\n",
    "        \r\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\r\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        x = x\r\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\r\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\r\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\r\n",
    "        out = self.fc(out[:, -1, :])\r\n",
    "        return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = LSTM(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_layers=num_layers)\r\n",
    "\r\n",
    "criterion = torch.nn.MSELoss(reduction='mean')\r\n",
    "\r\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=0.01)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import time\r\n",
    "\r\n",
    "hist = np.zeros(num_epochs)\r\n",
    "start_time = time.time()\r\n",
    "lstm = []\r\n",
    "\r\n",
    "for t in range(num_epochs):\r\n",
    "    y_train_pred = model(x_train)\r\n",
    "\r\n",
    "    loss = criterion(y_train_pred, y_train_lstm)\r\n",
    "    print(\"Epoch \", t, \"MSE: \", loss.item())\r\n",
    "    hist[t] = loss.item()\r\n",
    "\r\n",
    "    optimiser.zero_grad()\r\n",
    "    loss.backward()\r\n",
    "    optimiser.step()\r\n",
    "    \r\n",
    "training_time = time.time()-start_time\r\n",
    "print(\"Training time: {}\".format(training_time))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "predict = pd.DataFrame((y_train_pred.detach().numpy()))\r\n",
    "original = pd.DataFrame((y_train_lstm.detach().numpy()))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import seaborn as sns\r\n",
    "sns.set_style(\"darkgrid\")    \r\n",
    "\r\n",
    "fig = plt.figure()\r\n",
    "fig.subplots_adjust(hspace=0.2, wspace=0.2)\r\n",
    "\r\n",
    "plt.subplot(1, 2, 1)\r\n",
    "ax = sns.lineplot(x = original.index, y = original[0], label=\"Data\", color='royalblue')\r\n",
    "ax = sns.lineplot(x = predict.index, y = predict[0], label=\"Training Prediction (LSTM)\", color='tomato')\r\n",
    "ax.set_title('Stock price', size = 14, fontweight='bold')\r\n",
    "ax.set_xlabel(\"Days\", size = 14)\r\n",
    "ax.set_ylabel(\"Cost (USD)\", size = 14)\r\n",
    "ax.set_xticklabels('', size=10)\r\n",
    "\r\n",
    "\r\n",
    "plt.subplot(1, 2, 2)\r\n",
    "ax = sns.lineplot(data=hist, color='royalblue')\r\n",
    "ax.set_xlabel(\"Epoch\", size = 14)\r\n",
    "ax.set_ylabel(\"Loss\", size = 14)\r\n",
    "ax.set_title(\"Training Loss\", size = 14, fontweight='bold')\r\n",
    "fig.set_figheight(6)\r\n",
    "fig.set_figwidth(16)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "import math, time\r\n",
    "from sklearn.metrics import mean_squared_error\r\n",
    "\r\n",
    "# make predictions\r\n",
    "y_test_pred = model(x_test)\r\n",
    "\r\n",
    "# invert predictions\r\n",
    "y_train_pred = scaler.inverse_transform(y_train_pred.detach().numpy())\r\n",
    "y_train = scaler.inverse_transform(y_train_lstm.detach().numpy())\r\n",
    "y_test_pred = scaler.inverse_transform(y_test_pred.detach().numpy())\r\n",
    "y_test = scaler.inverse_transform(y_test_lstm.detach().numpy())\r\n",
    "\r\n",
    "# calculate root mean squared error\r\n",
    "trainScore = math.sqrt(mean_squared_error(y_train[:,0], y_train_pred[:,0]))\r\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\r\n",
    "testScore = math.sqrt(mean_squared_error(y_test[:,0], y_test_pred[:,0]))\r\n",
    "print('Test Score: %.2f RMSE' % (testScore))\r\n",
    "lstm.append(trainScore)\r\n",
    "lstm.append(testScore)\r\n",
    "lstm.append(training_time)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "32b750e31e5f8fdba07d0d8a6ffacb3770eea7b743b6e57a1a344d991206ea4c"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('Pytorch': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}